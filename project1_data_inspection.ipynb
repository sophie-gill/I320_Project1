{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I320 Project 1\n",
    "### Name: Sophie Gill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset\n",
    "\n",
    "**Dataset:** Wisconsin Diagnostic Breast Cancer (WDBC)  \n",
    "**Source:** UCI Machine Learning Repository / Kaggle  \n",
    "**File:** `data.csv`  \n",
    "**Target Variable:** `diagnosis` (M = Malignant, B = Benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38           122.8     1001.0   \n",
       "1    842517         M        20.57         17.77           132.9     1326.0   \n",
       "2  84300903         M        19.69         21.25           130.0     1203.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33            184.6      2019.0            0.1622   \n",
       "1  ...          23.41            158.8      1956.0            0.1238   \n",
       "2  ...          25.53            152.5      1709.0            0.1444   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Verify dataset is loaded\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 10-Point Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: The dataset contains 569 rows and 33 columns, with the rows signifying individual cases of a single Fine Needle Aspirate (FNA) biopsy sample from a breast mass, and the columns describing the different features measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Column Names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: The column names include id, diagnosis, and 10 base features (radius, texture, etc.), each with three suffixes: _mean, _se, and _worst. There is also an 'Unnamed: 32' column. The features follow a structured naming convention of [Characteristic] [Calculation Type]. Additionally, concavity, concave points, and fractal_dimension may need additional clinical research to understand how they are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           int64\n",
       "diagnosis                   object\n",
       "radius_mean                float64\n",
       "texture_mean               float64\n",
       "perimeter_mean             float64\n",
       "area_mean                  float64\n",
       "smoothness_mean            float64\n",
       "compactness_mean           float64\n",
       "concavity_mean             float64\n",
       "concave points_mean        float64\n",
       "symmetry_mean              float64\n",
       "fractal_dimension_mean     float64\n",
       "radius_se                  float64\n",
       "texture_se                 float64\n",
       "perimeter_se               float64\n",
       "area_se                    float64\n",
       "smoothness_se              float64\n",
       "compactness_se             float64\n",
       "concavity_se               float64\n",
       "concave points_se          float64\n",
       "symmetry_se                float64\n",
       "fractal_dimension_se       float64\n",
       "radius_worst               float64\n",
       "texture_worst              float64\n",
       "perimeter_worst            float64\n",
       "area_worst                 float64\n",
       "smoothness_worst           float64\n",
       "compactness_worst          float64\n",
       "concavity_worst            float64\n",
       "concave points_worst       float64\n",
       "symmetry_worst             float64\n",
       "fractal_dimension_worst    float64\n",
       "Unnamed: 32                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Data Types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: All columns are numeric (int64 or float64) except for diagnosis, which is categorical (object).\n",
    "There are no data types that appear incorrect; however, 'Unnamed: 32' is technically a float but contains no data as seen in the following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: First Look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: The actual values are standardized numerical measurements (mostly between 0 and 1 for SE/shape and much higher for area/perimeter). The diagnosis values are either M (Malignant) or B (Benign). The only unusual or unexpected values come from the 'Unnamed: 32' column as mentioned before, which is immediately visible as being full of NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564  926424         M        21.56         22.39          142.00     1479.0   \n",
       "565  926682         M        20.13         28.25          131.20     1261.0   \n",
       "566  926954         M        16.60         28.08          108.30      858.1   \n",
       "567  927241         M        20.60         29.33          140.10     1265.0   \n",
       "568   92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Last Look\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: There is a clean ending to the data; the indices end at 568 (for 569 total rows). The structure and formatting of the last rows are consistent and match the first rows completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                       132\n",
       "id                         4552\n",
       "diagnosis                  4552\n",
       "radius_mean                4552\n",
       "texture_mean               4552\n",
       "perimeter_mean             4552\n",
       "area_mean                  4552\n",
       "smoothness_mean            4552\n",
       "compactness_mean           4552\n",
       "concavity_mean             4552\n",
       "concave points_mean        4552\n",
       "symmetry_mean              4552\n",
       "fractal_dimension_mean     4552\n",
       "radius_se                  4552\n",
       "texture_se                 4552\n",
       "perimeter_se               4552\n",
       "area_se                    4552\n",
       "smoothness_se              4552\n",
       "compactness_se             4552\n",
       "concavity_se               4552\n",
       "concave points_se          4552\n",
       "symmetry_se                4552\n",
       "fractal_dimension_se       4552\n",
       "radius_worst               4552\n",
       "texture_worst              4552\n",
       "perimeter_worst            4552\n",
       "area_worst                 4552\n",
       "smoothness_worst           4552\n",
       "compactness_worst          4552\n",
       "concavity_worst            4552\n",
       "concave points_worst       4552\n",
       "symmetry_worst             4552\n",
       "fractal_dimension_worst    4552\n",
       "Unnamed: 32                4552\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Memory Usage\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: The dataset uses approximately 146.9 KB of memory (total sum of all columns). By data science standards, this would be considered a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: Only 'Unnamed: 32' has null/missing values, with 100% of the column missing. However, this does not indicate a suspicious pattern as it was likely created by a trailing comma error in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "564    False\n",
       "565    False\n",
       "566    False\n",
       "567    False\n",
       "568    False\n",
       "Length: 569, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Duplicates\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: There are no duplicate rows, and all 569 patient IDs are unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 9: Basic Statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: The radius_mean ranges from 6.981 to 28.11. The area_mean range is 143.5 to 2501.0, and the concavity_mean range is 0.0 to 0.4268. There aren't any values that appear impossible; however, a concavity of 0.0 is unusual but possible for perfectly smooth cell boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         569\n",
       "diagnosis                    2\n",
       "radius_mean                456\n",
       "texture_mean               479\n",
       "perimeter_mean             522\n",
       "area_mean                  539\n",
       "smoothness_mean            474\n",
       "compactness_mean           537\n",
       "concavity_mean             537\n",
       "concave points_mean        542\n",
       "symmetry_mean              432\n",
       "fractal_dimension_mean     499\n",
       "radius_se                  540\n",
       "texture_se                 519\n",
       "perimeter_se               533\n",
       "area_se                    528\n",
       "smoothness_se              547\n",
       "compactness_se             541\n",
       "concavity_se               533\n",
       "concave points_se          507\n",
       "symmetry_se                498\n",
       "fractal_dimension_se       545\n",
       "radius_worst               457\n",
       "texture_worst              511\n",
       "perimeter_worst            514\n",
       "area_worst                 544\n",
       "smoothness_worst           411\n",
       "compactness_worst          529\n",
       "concavity_worst            539\n",
       "concave points_worst       492\n",
       "symmetry_worst             500\n",
       "fractal_dimension_worst    535\n",
       "Unnamed: 32                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 10: Unique Counts\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: Diagnosis, being categorical, has few unique values (2). All the other measurement columns have many unique values (most with 400+). Additionally, the number of unique IDs does match the number of rows (569)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Dictionary\n",
    "\n",
    "Complete the following data dictionary for the **key columns**. For each column, you must:\n",
    "1. **Research** the clinical meaning\n",
    "2. **Identify** the feature type (Continuous, Discrete, Categorical-Nominal, Categorical-Ordinal, Binary, Identifier)\n",
    "3. **Document** the valid values/range you observe\n",
    "4. **Note** any issues or questions\n",
    "\n",
    "| Column | Description | Feature Type | Valid Values/Range | Notes/Issues |\n",
    "|--------|-------------|--------------|-------------------|--------------|\n",
    "| `id` |Unique patient identification number |Identifier |8670 - 911320502 |Unique for every row |\n",
    "| `diagnosis` |Tumor classification |Binary |{M, B} |Target variable |\n",
    "| `radius_mean` |Avg distance from nucleus center to points on perimeter |Continuous |6.981 - 28.11 |Larger = more likely malignant |\n",
    "| `texture_mean` |Standard deviation of gray-scale values |Continuous |9.71 - 39.28 |Larger = more irregular surface |\n",
    "| `perimeter_mean` |Boundary length of the nucleus |Continuous |43.79 - 188.5 |Correlated with radius |\n",
    "| `area_mean` |Area of the nucleus |Continuous |143.5 - 2501.0 |Malignant cells typically larger |\n",
    "| `smoothness_mean` |Local variation in radius lengths |Continuous |0.05263 - 0.1634 |Lower values = smoother borders, higher values = irregular borders |\n",
    "| `compactness_mean` |(perimeter² / area) - 1.0 |Continuous |0.01938 - 0.3454 |0 = perfectly circular, higher = more irregular |\n",
    "| `concavity_mean` |Severity of concave portions of the contour |Continuous |0.0 - 0.4268 |Higher = more indentations |\n",
    "| `concave points_mean` |Number of concave portions of the contour |Continuous |0.0 - 0.2012 |Malignant tumors have more concave points |\n",
    "| `symmetry_mean` |Symmetry of the nucleus |Continuous |0.106 - 0.304 |Lower = more symmetric/likely benign |\n",
    "| `fractal_dimension_mean` |Avg boundary complexity |Continuous |0.04996 - 0.09744 |Higher = more irregular border |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is computer-aided diagnosis (CAD) in radiology? How does it assist physicians in detecting breast cancer?**\n",
    "CAD is a technology that uses pattern recognition and other sophisticated algorithms to analyze medical images as a form of assistance or second opinion for radiologists. This is helpful as it reduces human error, picking out features that may have otherwise been overlooked. The software scans the images for specific indicators of cancer and makes any areas of concern known to the physician. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is the relationship between tumor size and prognosis in breast cancer? Why is early detection so important?**\n",
    "In breast cancer, tumor size is one of the most crucial factors for determining a patient's prognosis. There is a direct correlation between the size of the tumor and the patient's long-term survival rate - typically, the smaller the tumor, the more favorable the prognosis. Thus, identifying cancer before it becomes large enough to cause symptoms is ideal for improving survival. When breast cancer is detected early (still in the \"localized\" stage and confined to the breast), the 5-year relative survival rate is 99%. This drops sharply to around 30% if the cancer is diagnosed at an advanced, metastatic stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Explain what \"compactness\" measures mathematically (perimeter² / area - 1.0). Why might cancer cells have different compactness than normal cells?** Compactness is a shape-based metric that is used to describe the irregularity of a cell nucleus based on perimeter and area as shown in the formula perimeter² / area - 1.0. As perimeter increases, area stays relatively the same, causing the compactness value to rise. Physicians look for this irregular shape, as cancer cells have higher activity inside the nucleus that can cause the nuclear envelope to bulge or become distorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What is the difference between \"mean,\" \"standard error,\" and \"worst\" measurements in this dataset? Why might the \"worst\" values be particularly important for diagnosis?** In the context of this dataset, 'mean' represents the average value of a specific feature across all cell nuclei captured in the image, providing a baseline for the sample. 'Standard error' measures the variability or spread of the feature among the nuclei, with a high SE indicating the cell nuclei are inconsistent in size or shape. 'Worst' shows the mean of the three largest values recorded for a feature in the sample. This doesn't always constitute something 'bad', but shows the extreme end of the measurements. These 'worst' values are often the most important for diagnosis, as a tumor might have a small cluster of aggressive, irregular cells (indicating malignant growth) that are able to be identified when analyzing extreme values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Diagnosis Distribution Validation\n",
    "Write code to check:\n",
    "- How many patients have malignant (M) tumors?\n",
    "- How many patients have benign (B) tumors?\n",
    "- What is the percentage of each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis Counts:\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n",
      " \n",
      "Diagnosis Percentages:\n",
      "diagnosis\n",
      "B    62.741652\n",
      "M    37.258348\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get raw counts for M and B\n",
    "diagnosis_counts = df['diagnosis'].value_counts()\n",
    "\n",
    "# Get percentages\n",
    "diagnosis_percentages = df['diagnosis'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display results\n",
    "print(\"Diagnosis Counts:\")\n",
    "print(diagnosis_counts)\n",
    "print(\" \")\n",
    "print(\"Diagnosis Percentages:\")\n",
    "print(diagnosis_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: The dataset is imbalanced as there is a clear majority of benign cases. This distribution is okay because in real-world data, this imbalance is typically more prominent, with about 80% of breast biopsies turning out to be benign (American Cancer Society). Additionally, having more representation for malignant cases is beneficial for training a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Empty Column Validation \n",
    "\n",
    "Write code to examine all columns for any that might be completely empty or contain only null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "id                           0\n",
      "diagnosis                    0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in all columns\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: There are no empty columns in the dataset other than one named 'Unnamed: 32', which contains only null values. As it contains no data, this column should be dropped from the dataframe before continuing with any machine learning. Empty columns may exist in a dataset due to formatting issues, such as trailing commas in the CSV that are interpreted as an additional empty column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the empty column\n",
    "df = df.drop(columns=['Unnamed: 32'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Feature Range Validation\n",
    "Write code to check if the \"worst\" measurements are always greater than or equal to the \"mean\" measurements for the same characteristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is radius_worst always >= radius_mean? True\n",
      " \n",
      "Check for all feature pairs:\n",
      "radius              : True\n",
      "texture             : True\n",
      "perimeter           : True\n",
      "area                : True\n",
      "smoothness          : True\n",
      "compactness         : True\n",
      "concavity           : True\n",
      "concave points      : True\n",
      "symmetry            : True\n",
      "fractal_dimension   : True\n"
     ]
    }
   ],
   "source": [
    "# Check if 'worst' always >= to 'mean' for radius\n",
    "radius_check = (df['radius_worst'] >= df['radius_mean']).all()\n",
    "\n",
    "# Check for all relevant feature pairs\n",
    "features = ['radius', 'texture', 'perimeter', 'area', 'smoothness', \n",
    "            'compactness', 'concavity', 'concave points', 'symmetry', 'fractal_dimension']\n",
    "\n",
    "all_checks = {f: (df[f'{f}_worst'] >= df[f'{f}_mean']).all() for f in features}\n",
    "\n",
    "print(f\"Is radius_worst always >= radius_mean? {radius_check}\")\n",
    "print(\" \")\n",
    "print(\"Check for all feature pairs:\")\n",
    "for feature, result in all_checks.items():\n",
    "    print(f\"{feature:20}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: 'Radius_worst' is always greater than or equal to 'radius_mean'. As seen in the secondary part of the output, this logic also applies to all 10 characteristics in the dataset. The \"worst\" measurement consistently represents the extreme upper end of the distribution for each sample, meaning it will always be greater than or equal to the overall mean. If a 'mean' value were ever higher than a 'worst' value, it would indicate a data integrity error (this could be caused by things like calculation errors or data entry errors). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Create Clinical Area Groups\n",
    "Create a new column called `area_category` that categorizes tumors into clinically-meaningful groups based on `area_mean`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quartile-Based Categories\n",
    "Use these categories based on the quartile distribution of the data:\n",
    "\n",
    "| Area Category | Area Range | Clinical Rationale |\n",
    "|---------------|------------|-------------------|\n",
    "| Q1 - Smallest | < 25th percentile | Smallest tumors, likely early stage |\n",
    "| Q2 - Below Average | 25th to 50th percentile | Small tumors |\n",
    "| Q3 - Above Average | 50th to 75th percentile | Moderate size tumors |\n",
    "| Q4 - Largest | > 75th percentile | Largest tumors, may indicate advanced disease |\n",
    "\n",
    "**Hint:** First calculate the quartile values using `df['area_mean'].quantile([0.25, 0.50, 0.75])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartiles:\n",
      "0.25    420.3\n",
      "0.50    551.1\n",
      "0.75    782.7\n",
      "Name: area_mean, dtype: float64\n",
      "\n",
      "Counts per Area Category:\n",
      "area_category\n",
      "Q1 - Smallest         144\n",
      "Q2 - Below Average    141\n",
      "Q3 - Above Average    142\n",
      "Q4 - Largest          142\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the quartile values\n",
    "quartiles = df['area_mean'].quantile([0.25, 0.50, 0.75])\n",
    "print(\"Quartiles:\")\n",
    "print(quartiles)\n",
    "\n",
    "# Create the area_category column using qcut, define 4 bins\n",
    "df['area_category'] = pd.qcut(df['area_mean'], q=4, labels=['Q1 - Smallest', 'Q2 - Below Average', 'Q3 - Above Average', 'Q4 - Largest'])\n",
    "\n",
    "# Show distribution of area categories\n",
    "print(\"\\nCounts per Area Category:\")\n",
    "print(df['area_category'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malignancy Rate by Area Category:\n",
      "area_category\n",
      "Q1 - Smallest          2.083333\n",
      "Q2 - Below Average     9.929078\n",
      "Q3 - Above Average    41.549296\n",
      "Q4 - Largest          95.774648\n",
      "Name: diagnosis, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of malignant diagnoses in each area category\n",
    "malignancy_rates = df.groupby('area_category', observed=True)['diagnosis'].apply(lambda x: (x == 'M').mean() * 100)\n",
    "\n",
    "print(\"Malignancy Rate by Area Category:\")\n",
    "print(malignancy_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the actual quartile boundaries (area values) you calculated?**\n",
    "The quartile boundaries for area_mean are: 25th Percentile (Q1) - 420.3, 50th Percentile (Median) - 551.1, and 75th Percentile (Q3) - 782.7. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tumors are in each area category? (Should be approximately equal)**\n",
    "The distribution is nearly equal across the four categories, as expected with quartile splitting. Q1 - Smallest: 144, Q2 - Below Average: 141, Q3 - Above Average: 142, and Q4 - Largest: 142.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is the malignancy rate (percentage) for each area category?**\n",
    "As seen in the output, the malignancy rates for these specific bins are approximately:\n",
    "Q1 = 2%\n",
    "Q2 = 10%\n",
    "Q3 = 42%\n",
    "Q4 = 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. How does malignancy rate change as you move from Q1 to Q4? What does this suggest about the relationship between tumor area and diagnosis?**\n",
    "There is a dramatic, non-linear increase in the malignancy rate as the tumor area increases. While a tumor in the smallest quartile has a very low probability of being malignant, a tumor in the largest quartile is almost certainly malignant. This suggests a strong positive correlation between tumor size and malignancy, confirming that area_mean is a significant clinical predictor for breast cancer diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Write Three Answerable Questions \n",
    "Write three questions that THIS dataset can answer. Remember: the data can show relationships and patterns, but cannot prove causation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. A question about texture and diagnosis:**\n",
    "Is there a statistically significant difference in the average texture_mean between malignant and benign tumors, and does high texture variability correlate with a higher malignancy rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. A question about the standard error (_se) features:**\n",
    "How does the area_se (standard error of the area) compare between the four area_category quartiles, and do malignant tumors consistently show higher levels of measurement inconsistency (SE) than benign ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. A question about symmetry combined with another feature:**\n",
    "To what extent does the combination of low symmetry_mean and high compactness_mean increase the likelihood of a malignant diagnosis compared to just looking at symmetry alone?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Identify One Question the Data CANNOT Answer\n",
    "\n",
    "Write one question about patient demographics or survival that this dataset cannot answer, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the average age of patients diagnosed with malignant tumors, and how does their survival rate compare to those with benign tumors?\n",
    "\n",
    "**Why the data cannot answer this:**\n",
    "This dataset is focused strictly on image-based measurements of cell nuclei (fine needle aspirate features). It lacks any demographic data (there is no information regarding patient age, ethnicity, or medical history) or longitudinal/outcome data. The dataset only provides a \"snapshot\" diagnosis of Malignant/Benign at the time of the biopsy, it does not track patient outcomes, treatments, or survival length after the diagnosis was made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Grouping Analysis\n",
    "\n",
    "Answer this question using a groupby analysis: \n",
    "\n",
    "**\"What is the average compactness_mean for each diagnosis category (M vs B)?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Compactness Mean by Diagnosis:\n",
      "diagnosis\n",
      "B    0.080085\n",
      "M    0.145188\n",
      "Name: compactness_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average compactness_mean for Malignant (M) and Benign (B)\n",
    "compactness_analysis = df.groupby('diagnosis')['compactness_mean'].mean()\n",
    "\n",
    "print(\"Average Compactness Mean by Diagnosis:\")\n",
    "print(compactness_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation: How does compactness differ between malignant and benign tumors? What might explain this difference based on your understanding of what compactness measures?** The output shows that malignant tumors have a significantly higher average compactness (approximately 0.145) compared to benign tumors (approximately 0.080). In this dataset, the average malignant tumor is nearly twice as \"compact\" as a benign one. \n",
    "Based on the mathematical definition of compactness, a higher value indicates that the perimeter is much longer than it would be for a smooth, simple shape (like a circle) of the same area. Biologically, benign cells generally maintain regular, smooth oval shapes. In contrast, malignant cells grow rapidly, causing  the nuclear boundary to become jagged or \"bumpy.\" This increased surface irregularity spikes the perimeter measurement, leading to a higher compactness score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Target Variable Analysis (Bonus)\n",
    "\n",
    "The `diagnosis` column is our **target variable** - what we're trying to predict. Analyze its relationship with key features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis Distribution:\n",
      "diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary Statistics for Key Features:\n",
      "          radius_mean                  concavity_mean                    \\\n",
      "                 mean       std    max           mean       std     max   \n",
      "diagnosis                                                                 \n",
      "B           12.146524  1.780512  17.85       0.046058  0.043442  0.4108   \n",
      "M           17.462830  3.203971  28.11       0.160775  0.075019  0.4268   \n",
      "\n",
      "          perimeter_worst                    \n",
      "                     mean        std    max  \n",
      "diagnosis                                    \n",
      "B               87.005938  13.527091  127.1  \n",
      "M              141.370330  29.457055  251.2  \n"
     ]
    }
   ],
   "source": [
    "# Show the distribution of diagnosis\n",
    "diagnosis_dist = df['diagnosis'].value_counts()\n",
    "print(\"Diagnosis Distribution:\")\n",
    "print(diagnosis_dist)\n",
    "\n",
    "# Calculate summary statistics for 3 key features grouped by diagnosis\n",
    "key_features = ['radius_mean', 'concavity_mean', 'perimeter_worst']\n",
    "summary_stats = df.groupby('diagnosis')[key_features].agg(['mean', 'std', 'max'])\n",
    "\n",
    "print(\"\\nSummary Statistics for Key Features:\")\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What percentage of patients in this dataset have malignant tumors?** Based on the output in Part 3.1 and Part 6, there are 212 malignant cases out of 569 total patients - approximately 37.3%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Which feature shows the largest difference between malignant and benign tumors?** Of the three features analyzed in Part 6, perimeter_worst shows the largest absolute difference. The mean for benign tumors is about 87.0, while the mean for malignant tumors is about 141.4. This represents a large increase of over 60%, making it a very strong separator between the two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Why does class imbalance matter for machine learning classification? (You may need to research this)**\n",
    "Class imbalance (63% Benign vs. 37% Malignant here) matters because machine learning models are designed to maximize overall accuracy. If a dataset is heavily imbalanced, a model might simply learn to predict the majority class (Benign) every time to achieve high accuracy, while failing to actually identify the \"minority\" cases (Malignant). In a medical context, this is dangerous because a false negative (telling a sick patient they are healthy) is much worse than a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. If you were building a diagnostic model, which 3 features would you prioritize based on your analysis? Justify your choices.** One feature is area_mean (or area_worst) because the Part 4 analysis shows a near-perfect correlation with malignancy in the highest quartile (96% malignancy rate). Next, I would choose perimeter_worst because the \"worst\" measurements capture the most aggressive outliers in a tumor, providing the clearest numerical gap between B and M groups. Lastly, I would choose concavity_mean because the biological irregularity of cancer cells is captured here - the Part 6 stats show malignant tumors have over 3 times the average concavity of benign ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
